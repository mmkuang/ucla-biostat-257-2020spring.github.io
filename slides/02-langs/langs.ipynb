{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Languages (R, Python, Julia, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of computer languages\n",
    "\n",
    "* **Compiled languages** (low-level languages): C/C++, Fortran, ... \n",
    "  - Directly compiled to machine code that is executed by CPU \n",
    "  - Pros: fast, memory efficient\n",
    "  - Cons: longer development time, hard to debug\n",
    "\n",
    "* **Interpreted language** (high-level languages): R, Matlab, Python, SAS IML, JavaScript, ... \n",
    "  - Interpreted by interpreter\n",
    "  - Pros: fast prototyping\n",
    "  - Cons: excruciatingly slow for loops\n",
    "\n",
    "* Mixed (dynamic) languages: Matlab (JIT), R (`compiler` package), Julia, Cython, JAVA, ...\n",
    "  - Pros and cons: between the compiled and interpreted languages\n",
    "\n",
    "* Script languages: Linux shell scripts, Perl, ...\n",
    "  - Extremely useful for some data preprocessing and manipulation\n",
    "\n",
    "* Database languages: SQL, Hive (Hadoop).  \n",
    "  - Data analysis *never* happens if we do not know how to retrieve data from databases  \n",
    "  \n",
    "  [203B (Introduction to Data Science)](https://ucla-biostat203b-2020winter.github.io/schedule.html) covers some basics on scripting and database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How high-level languages work?\n",
    "\n",
    "- Typical execution of a high-level language such as R, Python, and Matlab.\n",
    "\n",
    "<img src=\"./r-bytecode.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "- To improve efficiency of interpreted languages such as R or Matlab, conventional wisdom is to avoid loops as much as possible. Aka, **vectorize code**\n",
    "> The only loop you are allowed to have is that for an iterative algorithm.\n",
    "\n",
    "- When looping is unavoidable, need to code in C, C++, or Fortran. This creates the notorious **two language problem**  \n",
    "Success stories: the popular `glmnet` package in R is coded in Fortran; `tidyverse` and `data.table` packages use a lot RCpp/C++.\n",
    "\n",
    "<img src=\"./two_language_problem.jpg\" align=\"center\" width=\"600\"/>\n",
    "\n",
    "- High-level languages have made many efforts to bring themselves closer to the performance of low-level languages such as C, C++, or Fortran, with a variety levels of success.   \n",
    "    - Matlab has employed JIT (just-in-time compilation) technology since 2002.  \n",
    "    - Since R 3.4.0 (Apr 2017), the JIT bytecode compiler is enabled by default at its level 3.   \n",
    "    - Cython is a compiler system based on Python.  \n",
    "\n",
    "- Modern languages such as Julia tries to solve the two language problem. That is to achieve efficiency without vectorizing code.\n",
    "\n",
    "- Julia execution.\n",
    "\n",
    "<img src=\"./julia_compile.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "<img src=\"./julia_introspect.png\" align=\"center\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs sampler example by Doug Bates\n",
    "\n",
    "- Doug Bates (member of R-Core, author of popular R packages `Matrix` and `lme4`)\n",
    "    \n",
    "    > As some of you may know, I have had a (rather late) mid-life crisis and run off with another language called Julia.   \n",
    "    >\n",
    "    > -- <cite>Doug Bates (on the `knitr` Google Group)</cite>\n",
    "\n",
    "- An example from Dr. Doug Bates's slides [Julia for R Programmers](http://www.stat.wisc.edu/~bates/JuliaForRProgrammers.pdf).\n",
    "\n",
    "- The task is to create a Gibbs sampler for the density  \n",
    "$$\n",
    "f(x, y) = k x^2 exp(- x y^2 - y^2 + 2y - 4x), x > 0\n",
    "$$\n",
    "using the conditional distributions\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "  X | Y &\\sim& \\Gamma \\left( 3, \\frac{1}{y^2 + 4} \\right) \\\\\n",
    "  Y | X &\\sim& N \\left(\\frac{1}{1+x}, \\frac{1}{2(1+x)} \\right).\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R solution. The `RCall.jl` package allows us to execute R code without leaving the `Julia` environment. We first define an R function `Rgibbs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (N, thin) \n",
       "{\n",
       "    mat <- matrix(0, nrow = N, ncol = 2)\n",
       "    x <- y <- 0\n",
       "    for (i in 1:N) {\n",
       "        for (j in 1:thin) {\n",
       "            x <- rgamma(1, 3, y * y + 4)\n",
       "            y <- rnorm(1, 1/(x + 1), 1/sqrt(2 * (x + 1)))\n",
       "        }\n",
       "        mat[i, ] <- c(x, y)\n",
       "    }\n",
       "    mat\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(Matrix)\n",
    "\n",
    "Rgibbs <- function(N, thin) {\n",
    "  mat <- matrix(0, nrow=N, ncol=2)\n",
    "  x <- y <- 0\n",
    "  for (i in 1:N) {\n",
    "    for (j in 1:thin) {\n",
    "      x <- rgamma(1, 3, y * y + 4) # 3rd arg is rate\n",
    "      y <- rnorm(1, 1 / (x + 1), 1 / sqrt(2 * (x + 1)))\n",
    "    }\n",
    "    mat[i,] <- c(x, y)\n",
    "  }\n",
    "  mat\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sample of size 10,000 with a thinning of 500. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{RealSxp}\n",
       "   user  system elapsed \n",
       " 25.976   1.782  28.269 \n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "system.time(Rgibbs(10000, 500))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a Julia function for the simple Gibbs sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jgibbs (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "function jgibbs(N, thin)\n",
    "    mat = zeros(N, 2)\n",
    "    x = y = 0.0\n",
    "    for i in 1:N\n",
    "        for j in 1:thin\n",
    "            x = rand(Gamma(3, 1 / (y * y + 4)))\n",
    "            y = rand(Normal(1 / (x + 1), 1 / sqrt(2(x + 1))))\n",
    "        end\n",
    "        mat[i, 1] = x\n",
    "        mat[i, 2] = y\n",
    "    end\n",
    "    mat\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the same number of samples. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.411166215"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jgibbs(100, 5); # warm-up\n",
    "@elapsed jgibbs(10000, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 40-80 fold speed up of `Julia` over `R` on this example, **with similar coding effort**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Julia, R, Python, and C\n",
    "\n",
    "To better understand how these languages work, we use a simple example: summing a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia\n",
    "\n",
    "`@time`, `@elapsed`, `@allocated` macros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.035964 seconds (76.55 k allocations: 3.836 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500060.34072352527"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random # standard library\n",
    "Random.seed!(123) # seed\n",
    "x = rand(1_000_000) # 1 million random numbers in [0, 1)\n",
    "\n",
    "@time sum(x) # first run includes compilation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000565 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500060.34072352527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(x) # no compilation time after first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00073795"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the runtime\n",
    "@elapsed sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just the allocation\n",
    "@allocated sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use package `BenchmarkTools.jl` for more robust benchmarking. Analog of `microbenchmark` or `bench` package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     274.836 μs (0.00% GC)\n",
       "  median time:      444.936 μs (0.00% GC)\n",
       "  mean time:        496.362 μs (0.00% GC)\n",
       "  maximum time:     3.650 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          9915\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "bm = @benchmark sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.444936"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics # standard library\n",
    "benchmark_result = Dict() # a dictionary to store median runtime (in milliseconds)\n",
    "benchmark_result[\"Julia builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "We would use the low-level C code as the baseline for copmarison. In Julia, we can easily run compiled C code using the `ccall` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Libdl\n",
    "\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -std=c99 -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500060.340723512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it gives same answer\n",
    "c_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     1.221 ms (0.00% GC)\n",
       "  median time:      1.500 ms (0.00% GC)\n",
       "  mean time:        1.551 ms (0.00% GC)\n",
       "  maximum time:     7.370 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          3199\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark c_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.500243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "benchmark_result[\"C\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, buildin sum\n",
    "\n",
    "Next we compare to the build in `sum` function in R, which is implemented using C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "   expr      min      lq   mean   median       uq      max neval\n",
       " sum(y) 1.238856 1.29021 1.4202 1.341087 1.485662 2.365598   100\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "y <- $x\n",
    "rbm <- microbenchmark(sum(y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.341087"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm # dataframe\n",
    "benchmark_result[\"R builtin\"] = median(rbm[!, :time]) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, handwritten loop\n",
    "\n",
    "Handwritten loop in R is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "     expr      min       lq     mean median       uq      max neval\n",
       " sum_r(y) 17.46106 18.40698 19.24281 18.958 19.82638 26.13243   100\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "sum_r <- function(x) {\n",
    "  s <- 0\n",
    "  for (xi in x) {\n",
    "    s <- s + xi\n",
    "  }\n",
    "  s\n",
    "}\n",
    "library(microbenchmark)\n",
    "y <- $x\n",
    "rbm <- microbenchmark(sum_r(y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.958004"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm # dataframe\n",
    "benchmark_result[\"R loop\"] = median(rbm[!, :time]) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, builtin sum\n",
    "\n",
    "Built in function `sum` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"3.7.6\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     157.292 ms (0.00% GC)\n",
       "  median time:      162.206 ms (0.00% GC)\n",
       "  mean time:        162.168 ms (0.00% GC)\n",
       "  maximum time:     173.395 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          31\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")\n",
    "bm = @benchmark $pysum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162.205624"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, handwritten loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     212.511 ms (0.00% GC)\n",
       "  median time:      221.725 ms (0.00% GC)\n",
       "  mean time:        224.079 ms (0.00% GC)\n",
       "  maximum time:     254.300 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          23\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "\n",
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\"\n",
    "\n",
    "bm = @benchmark $sum_py($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.724851"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, numpy\n",
    "\n",
    "Numpy is the high-performance scientific computing library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function sum at 0x1515c0950>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in sum function from Numpy \n",
    "numpy_sum = pyimport(\"numpy\").\"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  352 bytes\n",
       "  allocs estimate:  7\n",
       "  --------------\n",
       "  minimum time:     358.174 μs (0.00% GC)\n",
       "  median time:      513.776 μs (0.00% GC)\n",
       "  mean time:        559.687 μs (0.00% GC)\n",
       "  maximum time:     1.719 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          8814\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark $numpy_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.513776"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python numpy\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy performance is on a par with Julia build-in sum function. Both are about 3 times faster than C, possibly because of usage of [SIMD](https://en.wikipedia.org/wiki/SIMD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7-element Array{Pair{Any,Any},1}:\n",
       "  \"Julia builtin\" => 0.444936\n",
       "   \"Python numpy\" => 0.513776\n",
       "      \"R builtin\" => 1.341087\n",
       "              \"C\" => 1.500243\n",
       "         \"R loop\" => 18.958004\n",
       " \"Python builtin\" => 162.205624\n",
       "    \"Python loop\" => 221.724851"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(collect(benchmark_result), by=x->x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `C` and `R builtin` are the baseline C performance (gold standard).\n",
    "\n",
    "* `Python builtin` and `Python loop` are 80-100 fold slower than C because the loop is interpreted.\n",
    "\n",
    "* `R loop` is about 30 folder slower than C and indicates the performance of bytecode generated by its compiler package (turned on by default since R v3.4.0 (Apr 2017)). \n",
    "\n",
    "* `Julia builtin` and `Python numpy` are 3-4 folder faster than C because of SIMD (???)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511.7391357421875px",
    "width": "251.7391357421875px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "640.4212036132812px",
    "left": "0px",
    "right": "1210.6114501953125px",
    "top": "109.57880401611328px",
    "width": "211.99728393554688px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
